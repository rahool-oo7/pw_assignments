{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **ASSIGNMENT - DECISION TREE :**"
      ],
      "metadata": {
        "id": "vwvoNcf_UStj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**: What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n",
        "- Decision Tree is a model that makes decision by asking a series of questions about the data.\n",
        "- In classification, it splits the data step by step, until it reaches a final decision (class label)\n",
        "---\n",
        "\n",
        "**Question 2**: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n",
        "- Gini Impurity measures how often a random sample would be misclassified\n",
        "- Entropy measures disorder or uncertainty in data.\n",
        "- Lower impurity = better split. The tree picks splits that make child nodes purer\n",
        "---\n",
        "\n",
        "**Question 3**: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n",
        "- Pre-Pruning: Stops tree growth early (limiting depth) → Faster, avoids overfitting\n",
        "- Post-Pruning: Grows full tree, then removes weak branches → Keeps accuracy while simplifying\n",
        "---\n",
        "\n",
        "**Question 4**: What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n",
        "- Information Gain = reduction in impurity (Entropy or Gini) after a split\n",
        "- It helps the tree choose the feature that best separates the data\n",
        "---\n",
        "\n",
        "**Question 5**: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?\n",
        "- Uses: Medical diagnosis, credit scoring, fraud detection, marketing\n",
        "- Advantages: Easy to understand, works with both numeric and categorical data\n",
        "- Limitations: Can overfit, sensitive to noisy data\n",
        "---"
      ],
      "metadata": {
        "id": "IauLkc6sUVyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6**: Write a Python program to:\n",
        "- Load the Iris Dataset\n",
        "- Train a Decision Tree Classifier using the Gini criterion\n",
        "- Print the model’s accuracy and feature importances"
      ],
      "metadata": {
        "id": "_RYqN98MVG8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "model = DecisionTreeClassifier(criterion='gini')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print('Accuracy score:', accuracy_score(y_test, y_pred))\n",
        "print('Feature Importance', model.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppbFCXPQVOwk",
        "outputId": "e5abff34-2ac6-4bbd-ece1-d7abef145bd7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.9666666666666667\n",
            "Feature Importance [0.01253395 0.01880092 0.07584566 0.89281948]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7**: Write a Python program to:\n",
        "- Load the Iris Dataset\n",
        "- Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to a fully-grown tree."
      ],
      "metadata": {
        "id": "EUHjGjT0VPFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "model1 = DecisionTreeClassifier()\n",
        "model1.fit(X_train, y_train)\n",
        "y_pred1 = model1.predict(X_test)\n",
        "\n",
        "model2 = DecisionTreeClassifier(max_depth=3)\n",
        "model2.fit(X_train, y_train)\n",
        "y_pred2 = model2.predict(X_test)\n",
        "\n",
        "print('Normal Decision Tree Classifier:', accuracy_score(y_test, y_pred1))\n",
        "print('Depth 3 Decision Tree Classifier:', accuracy_score(y_test, y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rhurHuYVct7",
        "outputId": "bbdd94b9-3d7d-48fe-f33e-16de72611b68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Decision Tree Classifier: 0.9666666666666667\n",
            "Depth 3 Decision Tree Classifier: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8**: Write a Python program to:\n",
        "- Load the Boston Housing Dataset\n",
        "- Train a Decision Tree Regressor\n",
        "- Print the Mean Squared Error (MSE) and feature importances"
      ],
      "metadata": {
        "id": "-ttTTJvoVdDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print('Mean squared Error', mean_squared_error(y_test, y_pred))\n",
        "print('Feature Importance', model.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iegA3htVVi-P",
        "outputId": "d3f8e7c3-d943-4c23-ec4d-33a497827b07"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared Error 0.49865452532836724\n",
            "Feature Importance [0.50670517 0.05058811 0.0335729  0.02892374 0.03277802 0.14651809\n",
            " 0.09858541 0.10232857]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9**: Write a Python program to:\n",
        "- Load the Iris Dataset\n",
        "- Tune the Decision Tree’s max_depth and min_samples_split using GridSearchCV\n",
        "- Print the best parameters and the resulting model accuracy"
      ],
      "metadata": {
        "id": "diTuAqBAVjML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "params = {\n",
        "    'max_depth': [2, 3, 4, 5, 10],\n",
        "    'min_samples_split': [2, 3, 4, 5, 10]\n",
        "}\n",
        "model = DecisionTreeClassifier()\n",
        "grid = GridSearchCV(model, param_grid=params, cv=5, verbose=0)\n",
        "grid.fit(X_train, y_train)\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "\n",
        "print('Best parameters: ', grid.best_params_)\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cKReb7TVrOn",
        "outputId": "edc5a328-98c7-4575-9ac2-cc78fedf54e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:  {'max_depth': 4, 'min_samples_split': 3}\n",
            "Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10**: Imagine you’re working as a data scientist for a healthcare company that wants to predict whether a patient has a certain disease. You have a large dataset with mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "- Handle the missing values\n",
        "- Encode the categorical features\n",
        "- Train a Decision Tree model\n",
        "- Tune its hyperparameters\n",
        "- Evaluate its performance\n",
        "\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting."
      ],
      "metadata": {
        "id": "bSKAQ8juVrbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**:\n",
        "- Handle the missing values -> Drop high-missing columns, impute numeric with median, categorical with mode\n",
        "- Encode the categorical features -> One-Hot for nominal and Ordinal for ordered data\n",
        "- Train Decision Tree -> split data then fit the DecisionTreeClassifier on the preprocessed data\n",
        "- Tune Hyperparameters -> Using GridSearchCv for max_depth, min_sample_split, criterion and more\n",
        "- Evaluate performance -> Checking accuracy, recall, precision, confusion matrix, and even ROC-AUC\n",
        "\n",
        "\n",
        "####Business value provided by model:\n",
        "- Predict disease risk early therefore supports faster diagnosis, saves cost, improves patient outcomes"
      ],
      "metadata": {
        "id": "Q5i76GiMAZsj"
      }
    }
  ]
}